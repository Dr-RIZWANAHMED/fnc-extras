{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding numerical approximations to $\\pi$ has fascinated people for millenia. One famous formula is\n",
    "\n",
    "$$ \\frac{\\pi^2}{6} = 1 + \\frac{1}{2^2} + \\frac{1}{3^2} + \\cdots. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say $s_k$ is the sum of the first  terms of the series above, and $p_k = \\sqrt{6s_k}$. Here is a fancy way to compute these sequences in a compact code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1/k^2 for k=1:100] \n",
    "s = cumsum(a)        # cumulative summation\n",
    "p = @. sqrt(6*s)\n",
    "\n",
    "using Plots,LaTeXStrings\n",
    "plot(1:100,p,m=:o,leg=:none,xlabel=L\"k\",ylabel=L\"p_k\",title=\"Sequence convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph suggests that $p_k\\to \\pi$ but doesn't give much information about the rate of convergence. Let $\\epsilon_k=|\\pi-p_k|$ be the sequence of errors. By plotting the error sequence on a log-log scale, we can see a nearly linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = @. abs(pi-p)    # error sequence\n",
    "plot(1:100,ep,m=:o,l=nothing,\n",
    "    leg=:none,xaxis=(:log10,L\"k\"),yaxis=(:log10,\"error\"),title=\"Convergence of errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests a power-law relationship where $\\epsilon_k\\approx a k^b$, or $\\log \\epsilon_k \\approx b (\\log k) + \\log a$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1:100\n",
    "V = [ k.^0 log.(k) ]     # fitting matrix\n",
    "c = V \\ log.(ep)         # coefficients of linear fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the parameters $a$ and $b$ used above, we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show (a,b) = exp(c[1]),c[2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's tempting to conjecture that $b\\to -1$ asymptotically. Here is how the numerical fit compares to the original convergence curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot!(k,a*k.^b,l=:dash)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
